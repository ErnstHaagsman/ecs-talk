<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Django on ECS</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/eh.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">

				<section class="center">

					<div class="title_card">
						<h1>Deploying a<br>Django Application <br>to Amazon ECS</h1>
						<h2>Ernst Haagsman, JetBrains</h2>
					</div>
				</section>

				<section>
					<h2>About me</h2>
					<ul>
						<li>I live in Munich, Germany</li>
						<li>I'm a Product Marketing Manager for PyCharm</li>
						<li>I like good food</li>
					</ul>
				</section>


				<section>
					<h2>The Plan</h2>
					<ul>
						<li>What's our application?</li>
						<li>Where could we deploy it?</li>
						<li>Docker & Docker-compose</li>
						<li>Run it on ECS</li>
					</ul>
				</section>

				<section class="image">
					<img src="img/django_todo.jpg" alt="The application">
				</section>

				<section class="center">
					<h4>github.com/ErnstHaagsman/djangodocker</h4>
					<p>auth & celery branches</p>
				</section>

				<section>
					<h2>Deployment Alternatives</h2>
					<ul>
						<li>Heroku</li>
						<li>VPS providers (Linode, Digital Ocean)</li>
						<li>Amazon Lightsail</li>
						<li>Amazon EC2</li>
						<li>Azure</li>
						<li>Google Kubernetes Engine</li>
					</ul>

					<aside class="notes">
						<p>Heroku: simple but expensive</p>
						<p>VPS: medium flexibility, API quality may not be great</p>
						<p>Lightsail: VPS with upgrade potential</p>
						<p>EC2: Single box, multiple boxes</p>
						<p>Azure: like AWS, you could have a look to see if it works for you</p>
						<p>GKE: Kubernetes makes some things easy, AWS will also offer K8s soon</p>
					</aside>
				</section>

				<section>
					<div class="title_card">
						<h1>Let's get started!</h1>
					</div>
				</section>

				<section>
					<pre><code class="hljs bash">python manage.py runserver 0.0.0.0:8000</code></pre>
				</section>

				<section>
					<h3>./Dockerfile</h3>
					<pre><code data-trim>
						FROM python:3.6

						WORKDIR /app

						# By copying over requirements first, we make sure that Docker will cache
						# our installed requirements rather than reinstall them on every build
						COPY requirements.txt /app/requirements.txt
						RUN pip install -r requirements.txt

						# Now copy in our code, and run it
						COPY . /app
						EXPOSE 8000
						CMD python manage.py runserver 0.0.0.0:8000
					</code></pre>

					<aside class="notes">
						<ul>
							<li>Containers are basically lightweight VMs</li>
							<li>Provisioned with Dockerfile</li>
							<li>Layers</li>
							<li>Like git, removing a file in a later layer still big</li>
						</ul>
					</aside>
				</section>

				<section class="image">
					<img src="img/arch_basic.png" alt="Architecture">
				</section>

				<section>
					<h3>./docker-compose.yml</h3>
					<pre><code data-trim>
						version: '2'
						services:
						  web:
							build: .
							ports:
							 - "8000:8000"
							volumes:
							 - .:/app
							links:
							 - db

						  db:
							image: "postgres:9.6"
							ports:
							  - "5432:5432"
							environment:
							  POSTGRES_PASSWORD: hunter2
					</code></pre>

					<aside class="notes">
						<ul>
							<li>Get things from docker hub</li>
							<li>Their docs specify env vars</li>
							<li>Development overrides</li>
						</ul>
					</aside>
				</section>

				<section>
					<h3>12 Factor App</h3>
					<ul>
						<li>Dev/prod parity</li>
						<li>Store config in the environment</li>
						<li>And more</li>
					</ul>

					<aside class="notes">
						<a href="12factor.net">The Twelve Factors</a>
					</aside>
				</section>

				<section>
					<h3>Running locally</h3>
					<pre><code data-trim>
						docker-compose up --build
					</code></pre>
				</section>

				<section class="image">
					<video data-autoplay src="img/compose_cli_build.mp4"></video>
				</section>

				<section class="image">
					<img src="img/compose_pycharm.jpg" alt="Configuring Docker Compose in PyCharm">
				</section>

				<section class="center">
					<h2>Ready to go?</h2>
					<p class="fragment">Not yet :(</p>

					<aside class="notes">
						<p>We're still using Django's built-in server</p>
						<p>Switch to Gunicorn (or uwsgi, or anything else)</p>
					</aside>
				</section>

				<section>
					<h2>Switch to Gunicorn</h2>
					<pre><code data-trim>
						pip install gunicorn
						gunicorn --bind 0.0.0.0:8000 djangodocker.wsgi
					</code></pre>

					<aside class="notes">
						Just add gunicorn to requirements.txt, and change
						dockerfile (next slide)
					</aside>
				</section>

				<section>
					<h3>./Dockerfile</h3>
					<pre><code data-trim data-noescape>
						FROM python:3.6

						WORKDIR /app

						# By copying over requirements first, we make sure that Docker will cache
						# our installed requirements rather than reinstall them on every build
						COPY requirements.txt /app/requirements.txt
						RUN pip install -r requirements.txt

						# Now copy in our code, and run it
						COPY . /app
						EXPOSE 8000
						<del>CMD python manage.py runserver 0.0.0.0:8000</del>
						<mark>CMD gunicorn --bind 0.0.0.0:8000 djangodocker.wsgi</mark>
					</code></pre>

					<aside class="notes">
						<ul>
							<li>What about static files?</li>
						</ul>
					</aside>
				</section>

				<section>
					<h3>Nginx</h3>
					<p>Serve static files</p>
					<p>Reverse proxy Django</p>
				</section>

				<section class="image">
					<img src="img/arch_separate_nginx.png" alt="Nginx separated">
				</section>

				<section>
					<h3>Nginx on same container?</h3>
					<ul>
						<li>Load balancing</li>
						<li>Unix socket</li>
						<li>Is the load uneven?</li>
					</ul>

					<aside class="notes">
						Separate is difficult because you'd need to
						load balance twice.
						Same container allows use of unix socket.
						Argument for separate would be highly unequal
						load.
					</aside>
				</section>

				<section class="image">
					<img src="img/arch_basic.png" alt="Nginx on web container">
				</section>

				<section>
					<h3>Add nginx</h3>
					<pre><code data-trim data-noescape>
						FROM python:3.6<mark>-jessie</mark>

						WORKDIR /app

						<mark>RUN apt-get update && apt-get install --no-install-recommends -y nginx \
							&& rm -rf /var/lib/apt/lists/*</mark>

						# By copying over requirements first, we make sure that Docker will cache
						# our installed requirements rather than reinstall them on every build
						COPY requirements.txt /app/requirements.txt
						RUN pip install -r requirements.txt

						<mark>COPY nginx.conf /etc/nginx/nginx.conf
						RUN python -u manage.py collectstatic</mark>

						# Now copy in our code, and run it
						COPY . /app
						EXPOSE 8000
						<mark>CMD nginx && gunicorn --bind unix:/tmp/gunicorn.sock djangodocker.wsgi</mark>
					</code></pre>

					<aside class="notes">
						Complex apt statement, because we need to clean
						up after ourselves (or the image gets YUGE)

						We need the collectstatic because we now need to
						put static files in the right place for nginx
					</aside>
				</section>

				<section>
					<h3>nginx.conf</h3>
					<pre><code data-trim>
						http {

							upstream app_server {
								# fail_timeout=0 means we always retry an upstream even if it failed
								# to return a good HTTP response for UNIX domain socket setups
								server unix:/tmp/gunicorn.sock fail_timeout=0;
							}

							server {
								listen 8000 deferred;

								location /static/ {
								  root /var/www;
								}

								location / {
								  proxy_pass http://app_server;
								}
							}
						}
					</code></pre>

					<aside class="notes">
						This is an excerpt. See the repo for more.
					</aside>
				</section>

				<section>
					<h3>settings.py</h3>
					<pre><code data-trim>
						SECRET_KEY = os.environ['SECRET_KEY']

						_debug = os.environ.get('DEBUG', '0')
						DEBUG = _debug == '1'  # only switch on debug if the DEBUG env var is '1'

						ALLOWED_HOSTS = [os.environ['HOST']]

						DATABASES = {
							'default': {
								'ENGINE': 'django.db.backends.postgresql',
								'NAME': os.environ['DB_NAME'],
								'USER': os.environ['DB_USER'],
								'PASSWORD': os.environ['DB_PASSWORD'],
								'HOST': os.environ['DB_HOST']
							}
						}

						STATIC_ROOT = '/var/www/static'
					</code></pre>

					<aside class="notes">
						os.environ will raise KeyError if an env var is
						unset. What is the problem here?
						Remember collectstatic?
					</aside>
				</section>

				<section>
					<h3>Dockerfile</h3>
					<pre><code data-trim data-noescape>
						...

						COPY requirements.txt /app/requirements.txt
						RUN pip install -r requirements.txt

						ENV SECRET_KEY=INSECURE_PLACEHOLDER \
							HOST='*' \
							DB_HOST='PLACEHOLDER' \
							DB_NAME='PLACEHOLDER' \
							DB_USER='PLACEHOLDER' \
							DB_PASSWORD='PLACEHOLDER'

						...
					</code></pre>
				</section>

				<section class="center">
					<h3>Not shown:</h3>
					<p>Running as a non-root user</p>
					<p>Reducing the image size further</p>

					<aside class="notes">
						See the repo.

						Installing sudo, adding a user, lots of
						mkdir and chown, giving the user the right
						to start nginx as sudo.

						'python' image is 600+ MB. By switching from
						the python base to a Ubuntu base image, we can
						reduce the image size from 755 MB to 230 MB.
					</aside>
				</section>

				<section class="center">
					<div class="title_card">
						<h1>Amazon ECS</h1>
					</div>
				</section>

				<section>
					<h3>How to control AWS?</h3>
					<ul>
						<li>Query API</li>
						<li>AWS Management Console</li>
						<li>CLI</li>
						<li>Client libraries</li>
						<li>Terraform</li>
					</ul>

					<aside class="notes">
						Query API is straight up HTTP. Client library for Python: boto3 (or boto for those of you that
						still use Python 2).
					</aside>
				</section>

				<section>
					<h3>Concepts</h3>
					<ul>
						<li>Elastic Container Registry</li>
						<li>Task Definition</li>
						<li>Service</li>
						<li>Cluster</li>
					</ul>
				</section>


				<section class="image">
					<img src="img/ecr_create_repo.png" alt="Create a repository">

					<aside class="notes">
						ECR is very simple. It's just storage for your images.
						A docker repository is a single image with its variants and versions.
						A collection of repositories is called a registry.
					</aside>
				</section>

				<section class="image">
					<img src="img/ecr_push_instructions.png" alt="How to push an image to ECR">
				</section>

				<section class="image">
					<img src="img/ecs_architecture.png" alt="Architecture overview">

					<aside class="notes">
						Out of scope: multiple regions

						Subnets are in different availability zones

						Grey boxes represent containers. ECS handles both scaling up and down the ECS instances,
						and the placement of containers on those instances.
					</aside>
				</section>

				<section>
					<h3>Task Definition</h3>
					<pre><code data-trim>
						{
							'family': 'migrate',
							'containerDefinitions': [{
								'name': 'migrate',
								'image': '846266591173.dkr.ecr.eu-central-1.amazonaws.com/'
								         'djangotodo:latest',
								'command': [
									'python', 'manage.py', 'migrate'
								],
								'environment': [
									{
										'name': 'DATABASE_URL',
										'value': 'postgres://user:pass@host/db'
									}
								],
								'memory': 256,
							}]
						}
					</code></pre>

					<aside class="notes">
						This actually isn't badly written JSON, it's a Python dict.
						You can use the boto3 Python library to control AWS.

						DATABASE_URL is supported using a third party package, not Django default
					</aside>
				</section>


				<section>
					<h3>Service</h3>
					<pre><code data-trim>
						{
							'deploymentConfiguration': {
								'maximumPercent': 200,
								'minimumHealthyPercent': 50
							},
							'service': 'web-service',
							'cluster': 'name-of-my-cluster',
							'desiredCount': 3,
							'taskDefinition': 'web'
						}
					</code></pre>

					<aside class="notes">
						minimumHealthyPercent describes how many old tasks the scheduler may kill during deployment
						before the new service is running. MaximumPercent tells the scheduler how many it needs to
						kill.
					</aside>
				</section>
				
				<section class="image" data-transition="slide-in fade-out">
					<img src="img/ecs_service_deploy_1.png" alt="Task definition for deployment">

					<aside class="notes">
						Now as described in the service definition, we want three instances
					</aside>
				</section>

				<section class="image" data-transition="fade-in slide-out">
					<img src="img/ecs_service_deploy_2.png" alt="ECS deployed tasks">

					<aside class="notes">
						ECS will automatically place the tasks, as described in the service

						When one of the tasks stops, service will automatically restart
					</aside>
				</section>

				<section>
					<h3>Architectural Questions</h3>
					<ul>
						<li>Database</li>
						<li>Load Balancing</li>
					</ul>

					<aside class="notes">
						You could host both services in their own container, for load balancing even somewhat easy
						(no need to solve any persistency issues). For database considerably harder (container hosts
						are essentially ephemeral). We'll use Amazon provided versions of both.
					</aside>
				</section>

				<section class="image">
					<img src="img/layers.png" alt="Application layers">
				</section>

				<section>
					<h3>RDS</h3>
					<ul>
						<li>You configure credentials, redundancy, etc</li>
						<li>AWS will manage your DB instance</li>
						<li>AWS provides an endpoint</li>
					</ul>
				</section>

				<section class="image">
					<img src="img/elb_diagram.png" alt="ELB">

					<aside class="notes">
						ECS automatically registers and deregisters containers from the target group
						Additionally, ELB does health checks.
					</aside>
				</section>

				<section>
					<h3>ELB Types</h3>
					<ul>
						<li>Application Load Balancer (HTTP)</li>
						<li>Network Load Balancer (TCP)</li>
					</ul>

					<aside class="notes">
						I ran into an issue with NLB routing back to the same container hosts. Solution: use
						awsvpc for container networking. Unfortunately very restrictive, as we can only assign
						a couple of additional virtual network adapters to our host boxes.
					</aside>
				</section>

				<section>
					<h3>So if we...</h3>
					<p class="fragment">Spin up an RDS database</p>
					<p class="fragment">Create a Web ECS service, with the DB endpoint configured</p>
					<p class="fragment">And set up ELB for that service</p>
					<p class="fragment">Are we done?</p>

					<aside class="notes">
						Unfortunately not, AWS security!
					</aside>
				</section>

				<section>
					<h3>Security on AWS</h3>
					<ul>
						<li>Security Groups</li>
						<li>IAM</li>
					</ul>
				</section>


				<section class="image">
					<img src="img/vpc_sg_web.png" alt="Add inbound rule to security group">

					<aside class="notes">
						Allowing traffic from load balancer to ECS instances.
						A Security Groups defines which traffic is allowed to go to the host
						By default, all outbound traffic is permitted.
						Specify origin as IP (range) or other security group.
					</aside>
				</section>

				<section>
					<h3>Status</h3>
					<p class="fragment">Working application</p>
					<p class="fragment">Logs</p>
					<p class="fragment">Database migration</p>

					<aside class="notes">
						Although we now generally have a working application, it'd be nice to have logs
						Django actually needs us to migrate the database at this point.
					</aside>
				</section>

				<section class="image">
					<img src="img/ecs_task_definitions_add_container_3.png" alt="Configure logging for ECS task">

					<aside class="notes">
						Add the logging configuration to the task definition,
						and then attach the IAM policy to the ECS role.
					</aside>
				</section>

				<section>
					<h3>IAM Roles</h3>
					<p class="fragment">The CloudWatch API is an AWS API</p>
					<p class="fragment">You need to be authenticated to use APIs</p>
					<p class="fragment">IAM Roles are used to authenticate AWS resources</p>
					<p class="fragment">Policies are attached to IAM Users/Roles to give them rights</p>

					<aside class="notes">
						Technically, IAM roles are attached to "trusted entities".
					</aside>
				</section>

				<section>
					<h3>IAM Policy</h3>
					<pre><code data-trim>
						{
							"Version": "2012-10-17",
							"Statement": [
								{
									"Effect": "Allow",
									"Action": [
										"logs:CreateLogGroup",
										"logs:CreateLogStream",
										"logs:PutLogEvents",
										"logs:DescribeLogStreams",
										"logs:DescribeLogGroups"
									],
									"Resource": [
										"arn:aws:logs:*:*:*"
									]
								}
							]
						}
					</code></pre>
				</section>

				<section>
					<h3>Attach to the ECS Role</h3>
					<ul>
						<li>The containers are running on ECS instances</li>
						<li>The instance has a role</li>
						<li>`ecsInstanceRole` is created by the Cluster wizard</li>
					</ul>
				</section>
				
				<section class="image">
					<img src="img/iam_cloudwatch_policy_attached.png" alt="Attach the policy to the ECS role">

					<aside class="notes">
						Define the policy in 'Policies' on the left, then find the ECS Instance Role in the
						Roles overview.
					</aside>
				</section>

				<section class="image">
					<img src="img/cloudwatch_add_log_group.png" alt="Create Log Group">

					<aside class="notes">
						Next: Run the Migrate task
					</aside>
				</section>

				<section class="image">
					<img src="img/ecs_task_definitions_run_task.png" alt="Run task">
				</section>

				<section class="image">
					<img src="img/ecs_cluster_with_task.png" alt="Task pending">
				</section>

				<section class="image">
					<img src="img/ecs_task_details.png" alt="Task details">
				</section>

				<section class="image">
					<img src="img/ecs_task_details_containers.png" alt="Container details for task">
				</section>

				<section class="image">
					<img src="img/cloudwatch_migrate_logs.png" alt="Migration successful">
				</section>

				<section>
					<h3>Progress</h3>
					<ul>
						<li>We've applied migrations to our database</li>
						<li>Now we should create our web task</li>
						<li>Mostly the same</li>
						<li>Leave command empty</li>
						<li>Add a port binding to port 8000</li>
					</ul>

					<aside class="notes">
						The port binding should be using host port '0' which will dynamically allocate a port.
						Static allocation would prevent us from running multiple similar containers on the same EC2
						instance.

						Afterwards: create service
					</aside>
				</section>
				
				<section class="image">
					<img src="img/ecs_create_service_1.png" alt="Creating the service">
				</section>

				<section class="image">
					<img src="img/ecs_create_service_2a.png" alt="Creating the service">
				</section>

				<section class="image">
					<img src="img/elb_create_1.png" alt="Configure an Application Load Balancer">
				</section>

				<section class="image">
					<img src="img/elb_create_2.png" alt="Configure an Application Load Balancer">

					<aside class="notes">
						Make sure to pick the VPC used for ECS
					</aside>
				</section>

				<section class="image">
					<img src="img/elb_create_3.png" alt="Configure an Application Load Balancer">
				</section>

				<section class="image">
					<img src="img/elb_create_4.png" alt="Configure an Application Load Balancer">

					<aside class="notes">
						Make sure to pick a route that gives a 200 response, or configure ELB
						to accept another good response.
					</aside>
				</section>

				<section class="image">
					<img src="img/elb_create_5.png" alt="Configure an Application Load Balancer">

					<aside class="notes">
						Leave empty, ECS will manage this for us.
					</aside>
				</section>

				<section class="image">
					<img src="img/ecs_create_service_2b.png" alt="Configure service's load balancing">
				</section>

				<section class="image">
					<img src="img/ecs_create_service_3.png" alt="Configure target group">

					<aside class="notes">
						Make sure to choose the existing target group

						Afterwards, service will start, and be registered for the ELB.
					</aside>
				</section>

				<section class="image">
					<img src="img/elb_overview.png" alt="Overview of Elastic Load Balancing">
				</section>

				<section class="center">
					<h3>Victory?</h3>
				</section>

				<section class="image">
					<img src="img/elb_502_sad.png" alt="502 Bad Gateway">

					<aside class="notes">
						Anyone know why we're getting this?

						Logs on next slide
					</aside>
				</section>

				<section class="image">
					<img src="img/cloudwatch_web_log_after_502.png" alt="Hint">
				</section>


				<section class="image">
					<img src="img/django_todo.jpg" alt="Victory!">
				</section>

				<section class="center">
					<h3>Now how to create a super user?</h3>
					<p class="fragment">ECS instances are regular EC2 instances</p>
				</section>
				
				<section class="image">
					<img src="img/vpc_sg_ssh.png" alt="ECS Security Group">

					<aside class="notes">
						Allow inbound SSH traffic
					</aside>
				</section>

				<section class="image">
					<img src="img/django_createsuperuser.png" alt="Create super user">

					<aside class="notes">
						<ul>
							<li>Find an instance that's running a web container</li>
							<li><code>docker ps</code> to find the container ID</li>
							<li><code>docker exec -it &lt;ID&gt; /bin/bash</code></li>
						</ul>
					</aside>
				</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				controls: false,
				width: 1920,
				height: 1080,
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
