<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Django on ECS</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/eh.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">

				<section class="center">

					<div class="title_card">
						<h1>Deploying a<br>Django Application <br>to Amazon ECS</h1>
						<h2>Ernst Haagsman, JetBrains</h2>
					</div>
				</section>

				<section>
					<h2>About me</h2>
					<ul>
						<li>I live in Munich, Germany</li>
						<li>I'm a Product Marketing Manager for PyCharm</li>
						<li>I like good food</li>
					</ul>
				</section>


				<section>
					<h2>The Plan</h2>
					<ul>
						<li>What's our application?</li>
						<li>Where could we deploy it?</li>
						<li>Docker & Docker-compose</li>
						<li>Run it on ECS</li>
					</ul>
				</section>

				<section class="image">
					<img src="img/django_todo.jpg" alt="The application">
				</section>

				<section class="center">
					<h4>github.com/ErnstHaagsman/djangodocker</h4>
					<p>auth & celery branches</p>
				</section>

				<section>
					<h2>Deployment Alternatives</h2>
					<ul>
						<li>Heroku</li>
						<li>VPS providers (Linode, Digital Ocean)</li>
						<li>Amazon Lightsail</li>
						<li>Amazon EC2</li>
						<li>Azure</li>
						<li>Google Kubernetes Engine</li>
					</ul>

					<aside class="notes">
						<p>Heroku: simple but expensive</p>
						<p>VPS: medium flexibility, API quality may not be great</p>
						<p>Lightsail: VPS with upgrade potential</p>
						<p>EC2: Single box, multiple boxes</p>
						<p>Azure: like AWS, you could have a look to see if it works for you</p>
						<p>GKE: Kubernetes makes some things easy, AWS will also offer K8s soon</p>
					</aside>
				</section>

				<section>
					<div class="title_card">
						<h1>Let's get started!</h1>
					</div>
				</section>

				<section>
					<pre><code class="hljs bash">python manage.py runserver 0.0.0.0:8000</code></pre>
				</section>

				<section>
					<h3>./Dockerfile</h3>
					<pre><code data-trim>
						FROM python:3.6

						WORKDIR /app

						# By copying over requirements first, we make sure that Docker will cache
						# our installed requirements rather than reinstall them on every build
						COPY requirements.txt /app/requirements.txt
						RUN pip install -r requirements.txt

						# Now copy in our code, and run it
						COPY . /app
						EXPOSE 8000
						CMD python manage.py runserver 0.0.0.0:8000
					</code></pre>

					<aside class="notes">
						<ul>
							<li>Containers are basically lightweight VMs</li>
							<li>Provisioned with Dockerfile</li>
							<li>Layers</li>
							<li>Like git, removing a file in a later layer still big</li>
						</ul>
					</aside>
				</section>

				<section class="image">
					<img src="img/arch_basic.png" alt="Architecture">
				</section>

				<section>
					<h3>./docker-compose.yml</h3>
					<pre><code data-trim>
						version: '2'
						services:
						  web:
							build: .
							ports:
							 - "8000:8000"
							volumes:
							 - .:/app
							links:
							 - db

						  db:
							image: "postgres:9.6"
							ports:
							  - "5432:5432"
							environment:
							  POSTGRES_PASSWORD: hunter2
					</code></pre>

					<aside class="notes">
						<ul>
							<li>Get things from docker hub</li>
							<li>Their docs specify env vars</li>
							<li>Development overrides</li>
						</ul>
					</aside>
				</section>

				<section>
					<h3>12 Factor App</h3>
					<ul>
						<li>Dev/prod parity</li>
						<li>Store config in the environment</li>
						<li>And more</li>
					</ul>

					<aside class="notes">
						<a href="12factor.net">The Twelve Factors</a>
					</aside>
				</section>

				<section>
					<h3>Running locally</h3>
					<pre><code data-trim>
						docker-compose up --build
					</code></pre>
				</section>

				<section class="image">
					<video data-autoplay src="img/compose_cli_build.mp4"></video>
				</section>

				<section class="image">
					<img src="img/compose_pycharm.jpg" alt="Configuring Docker Compose in PyCharm">
				</section>

				<section class="center">
					<h2>Django Development Server</h2>

					<q class="fragment">DO NOT USE THIS SERVER IN A PRODUCTION SETTING</q>

					<aside class="notes">
						<p>We're still using Django's built-in server</p>
						<p>Switch to Gunicorn (or uwsgi, or anything else)</p>
					</aside>
				</section>

				<section>
					<h2>Switch to Gunicorn</h2>
					<pre><code data-trim>
						pip install gunicorn
						gunicorn --bind 0.0.0.0:8000 djangodocker.wsgi
					</code></pre>

					<aside class="notes">
						Just add gunicorn to requirements.txt, and change
						dockerfile (next slide)
					</aside>
				</section>

				<section>
					<h3>./Dockerfile</h3>
					<pre><code data-trim data-noescape>
						FROM python:3.6

						WORKDIR /app

						# By copying over requirements first, we make sure that Docker will cache
						# our installed requirements rather than reinstall them on every build
						COPY requirements.txt /app/requirements.txt
						RUN pip install -r requirements.txt

						# Now copy in our code, and run it
						COPY . /app
						EXPOSE 8000
						<del>CMD python manage.py runserver 0.0.0.0:8000</del>
						<mark>CMD gunicorn --bind 0.0.0.0:8000 djangodocker.wsgi</mark>
					</code></pre>

					<aside class="notes">
						<ul>
							<li>What about static files?</li>
						</ul>
					</aside>
				</section>

				<section>
					<h3>Nginx</h3>
					<p>Serve static files</p>
					<p>Reverse proxy Django</p>
				</section>

				<section class="image">
					<img src="img/arch_separate_nginx.png" alt="Nginx separated">
				</section>

				<section>
					<h3>Nginx on same container?</h3>
					<ul>
						<li>Load balancing</li>
						<li>Unix socket</li>
						<li>Is the load uneven?</li>
					</ul>

					<aside class="notes">
						Separate is difficult because you'd need to
						load balance twice.
						Same container allows use of unix socket.
						Argument for separate would be highly unequal
						load.
					</aside>
				</section>

				<section class="image">
					<img src="img/arch_basic.png" alt="Nginx on web container">
				</section>

				<section>
					<h3>Add nginx</h3>
					<pre><code data-trim data-noescape>
						FROM python:3.6<mark>-jessie</mark>

						WORKDIR /app

						<mark>RUN apt-get update && apt-get install --no-install-recommends -y nginx \
							&& rm -rf /var/lib/apt/lists/*</mark>

						# By copying over requirements first, we make sure that Docker will cache
						# our installed requirements rather than reinstall them on every build
						COPY requirements.txt /app/requirements.txt
						RUN pip install -r requirements.txt

						<mark>COPY nginx.conf /etc/nginx/nginx.conf
						RUN python -u manage.py collectstatic</mark>

						# Now copy in our code, and run it
						COPY . /app
						EXPOSE 8000
						<mark>CMD nginx && gunicorn --bind unix:/tmp/gunicorn.sock djangodocker.wsgi</mark>
					</code></pre>

					<aside class="notes">
						Complex apt statement, because we need to clean
						up after ourselves (or the image gets YUGE)

						We need the collectstatic because we now need to
						put static files in the right place for nginx
					</aside>
				</section>

				<section>
					<h3>nginx.conf</h3>
					<pre><code data-trim>
						http {

							upstream app_server {
								# fail_timeout=0 means we always retry an upstream even if it failed
								# to return a good HTTP response for UNIX domain socket setups
								server unix:/tmp/gunicorn.sock fail_timeout=0;
							}

							server {
								listen 8000 deferred;

								location /static/ {
								  root /var/www;
								}

								location / {
								  proxy_pass http://app_server;
								}
							}
						}
					</code></pre>

					<aside class="notes">
						This is an excerpt. See the repo for more.
					</aside>
				</section>

				<section>
					<h3>settings.py</h3>
					<pre><code data-trim>
						SECRET_KEY = os.environ['SECRET_KEY']

						_debug = os.environ.get('DEBUG', '0')
						DEBUG = _debug == '1'  # only switch on debug if the DEBUG env var is '1'

						ALLOWED_HOSTS = [os.environ['HOST']]

						DATABASES = {
							'default': {
								'ENGINE': 'django.db.backends.postgresql',
								'NAME': os.environ['DB_NAME'],
								'USER': os.environ['DB_USER'],
								'PASSWORD': os.environ['DB_PASSWORD'],
								'HOST': os.environ['DB_HOST']
							}
						}

						STATIC_ROOT = '/var/www/static'
					</code></pre>

					<aside class="notes">
						os.environ will raise KeyError if an env var is
						unset. What is the problem here?
						Remember collectstatic?
					</aside>
				</section>

				<section>
					<h3>Dockerfile</h3>
					<pre><code data-trim data-noescape>
						...

						COPY requirements.txt /app/requirements.txt
						RUN pip install -r requirements.txt

						ENV SECRET_KEY=INSECURE_PLACEHOLDER \
							HOST='*' \
							DB_HOST='PLACEHOLDER' \
							DB_NAME='PLACEHOLDER' \
							DB_USER='PLACEHOLDER' \
							DB_PASSWORD='PLACEHOLDER'

						...
					</code></pre>
				</section>

				<section class="center">
					<h3>Not shown:</h3>
					<p>Running as a non-root user</p>
					<p>Reducing the image size further</p>

					<aside class="notes">
						See the repo.

						Installing sudo, adding a user, lots of
						mkdir and chown, giving the user the right
						to start nginx as sudo.

						'python' image is 600+ MB. By switching from
						the python base to a Ubuntu base image, we can
						reduce the image size from 755 MB to 230 MB.
					</aside>
				</section>

				<section class="center">
					<div class="title_card">
						<h1>Amazon ECS</h1>
					</div>
				</section>

				<section>
					<h3>How to control AWS?</h3>
					<ul>
						<li>Query API</li>
						<li>AWS Management Console</li>
						<li>CLI</li>
						<li>Client libraries</li>
						<li>Terraform</li>
					</ul>

					<aside class="notes">
						Query API is straight up HTTP. Client library for Python: boto3 (or boto for those of you that
						still use Python 2).
					</aside>
				</section>

				<section>
					<h3>Concepts</h3>
					<ul>
						<li>Elastic Container Registry</li>
						<li>Task Definition</li>
						<li>Service</li>
						<li>Cluster</li>
					</ul>
				</section>


				<section class="image">
					<img src="img/ecr_create_repo.png" alt="Create a repository">

					<aside class="notes">
						ECR is very simple. It's just storage for your images.
						A docker repository is a single image with its variants and versions.
						A collection of repositories is called a registry.
					</aside>
				</section>

				<section class="image">
					<img src="img/ecr_push_instructions.png" alt="How to push an image to ECR">
				</section>

				<section class="image">
					<img src="img/ecs_architecture.png" alt="Architecture overview">

					<aside class="notes">
						Out of scope: multiple regions

						Subnets are in different availability zones

						Grey boxes represent containers. ECS handles both scaling up and down the ECS instances,
						and the placement of containers on those instances.
					</aside>
				</section>

				<section>
					<h3>Task Definition</h3>
					<pre><code data-trim>
						{
							'family': 'migrate',
							'containerDefinitions': [{
								'name': 'migrate',
								'image': '846266591173.dkr.ecr.eu-central-1.amazonaws.com/'
								         'djangotodo:latest',
								'command': [
									'python', 'manage.py', 'migrate'
								],
								'environment': [
									{
										'name': 'DATABASE_URL',
										'value': 'postgres://user:pass@host/db'
									}
								],
								'memory': 256,
							}]
						}
					</code></pre>

					<aside class="notes">
						This actually isn't badly written JSON, it's a Python dict.
						You can use the boto3 Python library to control AWS.

						DATABASE_URL is supported using a third party package, not Django default
					</aside>
				</section>


				<section>
					<h3>Service</h3>
					<pre><code data-trim>
						{
							'deploymentConfiguration': {
								'maximumPercent': 200,
								'minimumHealthyPercent': 50
							},
							'service': 'web-service',
							'cluster': 'name-of-my-cluster',
							'desiredCount': 3,
							'taskDefinition': 'web'
						}
					</code></pre>

					<aside class="notes">
						<strong>Load balancing is also configured on the service!</strong>

						minimumHealthyPercent describes how many old tasks the scheduler may kill during deployment
						before the new service is running. MaximumPercent tells the scheduler how many it needs to
						kill.
					</aside>
				</section>
				
				<section class="image" data-transition="slide-in fade-out">
					<img src="img/ecs_service_deploy_1.png" alt="Task definition for deployment">

					<aside class="notes">
						Now as described in the service definition, we want three instances
					</aside>
				</section>

				<section class="image" data-transition="fade-in slide-out">
					<img src="img/ecs_service_deploy_2.png" alt="ECS deployed tasks">

					<aside class="notes">
						ECS will automatically place the tasks, as described in the service

						When one of the tasks stops, service will automatically restart
					</aside>
				</section>

				<section>
					<h3>Architectural Questions</h3>
					<ul>
						<li>Database</li>
						<li>Load Balancing</li>
					</ul>

					<aside class="notes">
						You could host both services in their own container, for load balancing even somewhat easy
						(no need to solve any persistency issues). For database considerably harder (container hosts
						are essentially ephemeral). We'll use Amazon provided versions of both.

						Load balancing is needed if you want smooth version changes, even if you're only running
						a single container.
					</aside>
				</section>

				<section class="image">
					<img src="img/layers.png" alt="Application layers">
				</section>

				<section>
					<h3>RDS</h3>
					<ul>
						<li>You configure credentials, redundancy, etc</li>
						<li>AWS will manage your DB instance</li>
						<li>AWS provides an endpoint</li>
					</ul>
				</section>

				<section class="image">
					<img src="img/elb_diagram.png" alt="ELB">

					<aside class="notes">
						ECS automatically registers and deregisters containers from the target group
						Additionally, ELB does health checks.
					</aside>
				</section>

				<section>
					<h3>ELB Types</h3>
					<ul>
						<li>Application Load Balancer (HTTP)</li>
						<li>Network Load Balancer (TCP)</li>
					</ul>

					<aside class="notes">
						I ran into an issue with NLB routing back to the same container hosts. Solution: use
						awsvpc for container networking. Unfortunately very restrictive, as we can only assign
						a couple of additional virtual network adapters to our host boxes.
					</aside>
				</section>

				<section>
					<h3>Security on AWS</h3>
					<ul>
						<li>Security Groups</li>
					</ul>
				</section>


				<section class="image">
					<img src="img/vpc_sg_web.png" alt="Add inbound rule to security group">

					<aside class="notes">
						Allowing traffic from load balancer to ECS instances.
						A Security Groups defines which traffic is allowed to go to the host
						By default, all outbound traffic is permitted.
						Specify origin as IP (range) or other security group.
					</aside>
				</section>

				<section>
					<h3>Status</h3>
					<p class="fragment">Working application</p>
					<p class="fragment">Logs</p>
					<p class="fragment">manage.py tasks</p>

					<aside class="notes">
						Although we now generally have a working application, it'd be nice to have logs
						Django actually needs us to migrate the database at this point.
					</aside>
				</section>

				<section class="image">
					<img src="img/ecs_task_definitions_add_container_3.png" alt="Configure logging for ECS task">

					<aside class="notes">
						Add the logging configuration to the task definition,
						and then attach the IAM policy to the ECS role.
					</aside>
				</section>

				<section>
					<h3>IAM Roles</h3>
					<p class="fragment">The CloudWatch API is an AWS API</p>
					<p class="fragment">You need to be authenticated to use APIs</p>
					<p class="fragment">IAM Roles are used to authenticate AWS resources</p>
					<p class="fragment">Policies are attached to IAM Users/Roles to give them rights</p>

					<aside class="notes">
						Technically, IAM roles are attached to "trusted entities".
					</aside>
				</section>

				<section>
					<h3>IAM Policy</h3>
					<pre><code data-trim>
						{
							"Version": "2012-10-17",
							"Statement": [
								{
									"Effect": "Allow",
									"Action": [
										"logs:CreateLogGroup",
										"logs:CreateLogStream",
										"logs:PutLogEvents",
										"logs:DescribeLogStreams",
										"logs:DescribeLogGroups"
									],
									"Resource": [
										"arn:aws:logs:*:*:*"
									]
								}
							]
						}
					</code></pre>
				</section>

				<section>
					<h3>Attach to the ECS Role</h3>
					<ul>
						<li>The containers are running on ECS instances</li>
						<li>The instance has a role</li>
						<li>`ecsInstanceRole` is created by the Cluster wizard</li>
					</ul>
				</section>
				
				<section class="image">
					<img src="img/iam_cloudwatch_policy_attached.png" alt="Attach the policy to the ECS role">

					<aside class="notes">
						Define the policy in 'Policies' on the left, then find the ECS Instance Role in the
						Roles overview.
					</aside>
				</section>

				<section class="image">
					<img src="img/cloudwatch_add_log_group.png" alt="Create Log Group">
				</section>

				<section class="center">
					<h3>Now how to run manage.py tasks?</h3>
					<p class="fragment">Create a custom task, or:</p>
					<p class="fragment">ECS instances are regular EC2 instances</p>
					<p class="fragment">No magic. Just connect with SSH.</p>

					<aside class="notes">
						Make sure to configure the key pair when creating the cluster though!
					</aside>
				</section>
				
				<section class="image">
					<img src="img/vpc_sg_ssh.png" alt="ECS Security Group">

					<aside class="notes">
						Allow inbound SSH traffic.
						Whenever having network trouble on AWS: check the SGs!
					</aside>
				</section>

				<section class="image">
					<img src="img/django_createsuperuser.png" alt="Create super user">

					<aside class="notes">
						<ul>
							<li>Find an instance that's running a web container</li>
							<li><code>docker ps</code> to find the container ID</li>
							<li><code>docker exec -it &lt;ID&gt; /bin/bash</code></li>
						</ul>

						<p>If non-interactive: create task definition</p>
					</aside>
				</section>

				<section>
					<h3>How to push a new version?</h3>
					<p class="fragment">Run ECR commands to push a new image</p>
					<p class="fragment">Create new revision of task definition</p>
					<p class="fragment">Update service</p>
					<p class="fragment">Let's do this with Python</p>
				</section>

				<section>
					<h3>AWS API Authentication</h3>
					<pre><code data-trim>
						aws configure

						# creates ~/.aws/credentials
					</code></pre>

					<aside class="notes">
						Make sure to use an IAM user. Ideally with the least amount of privileges.
					</aside>
				</section>

				<section>
					<h3>deploy.ps1</h3>
					<pre><code data-trim>
						Invoke-Expression -Command (aws ecr get-login --no-include-email --region eu-central-1)

						docker build -t djangotodo .

						docker tag djangotodo:latest \
							846266591173.dkr.ecr.eu-central-1.amazonaws.com/djangotodo:latest

						docker push 846266591173.dkr.ecr.eu-central-1.amazonaws.com/djangotodo:latest
					</code></pre>

					<aside class="notes">
						These are basically just the commands from the ECR page.
						This is PowerShell, which I'm using on Windows. Same thing in Bash
						would be very similar.
					</aside>
				</section>

				<section>
					<h3>Deploy Script</h3>
					<pre><code data-trim>
						subprocess.run(['powershell.exe', '.\deploy.ps1'])

						ecs_client = boto3.client('ecs')

						ecs_client.register_task_definition(
							family='web',
							containerDefinitions=[
								...
							]
						)

						ecs_client.update_service(
							service='web-service',
							cluster='clustername',
							desiredCount=2,
							taskDefinition='web'
						)
					</code></pre>

					<aside class="notes">
						Abbreviated example. It makes sense to check the state at some places for a production
						version. Also, import statements.
					</aside>
				</section>

				<section>
					<h3>Container Definition</h3>
					<pre><code data-trim>
						{
							'name': 'web',
							'image': '846266591173.dkr.ecr.eu-central-1.amazonaws.com/djangotodo:latest',
							'portMappings': [
							{
								'containerPort': 8000,
								'hostPort': 0,
								'protocol': 'tcp'
							}],
							'logConfiguration': {
								'logDriver': 'awslogs',
								'options': {
									'awslogs-group': 'djangotodo',
									'awslogs-region': 'eu-central-1',
									'awslogs-stream-prefix': 'web'
								}
							},
							'environment': [ ... ],
							'memory': 256,
						}
					</code></pre>
				</section>

				<section>
					<h3>Environment</h3>
					<pre><code data-trim>
						[
							{
								'name': 'DB_HOST',
								'value': 'djangotodo.fbuvek2gj.eu-central-1.rds.amazonaws.com'
							},
							{
								'name': 'DB_USER',
								'value': 'postgres'
							},
							{
								'name': 'DB_PASSWORD',
								'value': 'hunter2'
							},
							...
						]
					</code></pre>
				</section>

				<section class="center">
					<div class="title_card">
						<h1>Service Discovery</h1>
					</div>
				</section>

				<section>
					<h3>Let's add Celery</h3>
					<p class="fragment">Celery allows us to schedule tasks</p>
					<p class="fragment">Works with queue</p>
				</section>

				<section class="image">
					<img src="img/arch_queue.png" alt="Architecture with Celery">

					<aside class="notes">
						The problem: our 'queue' task gets placed somewhere by ECS
						and we don't know its IP (and port if we dynamically assign it) :(.
					</aside>
				</section>

				<section>
					<h3>Service Discovery</h3>
					<p>DNS</p>
					<p>Consul</p>
					<p>Etcd</p>
				</section>

				<section>
					<h3>DNS: Route 53</h3>
					<p class="fragment">Internally, any domain name can be used</p>
					<p class="fragment">No ELB-style integration with ECS</p>
					<p class="fragment">We can glue it together ourselves with Lambda</p>
				</section>

				<section>
					<h3>Lambda</h3>
					<p class="fragment">"serverless"</p>
					<p class="fragment">Just a Python script</p>
					<p class="fragment">Triggered with CloudWatch Events</p>
					<p class="fragment">Uses IAM role to be able to use APIs</p>

					<aside class="notes">
						CloudWatch has task started and task stopped events. Unfortunately, the task stopped
						isn't fired when you kill the ECS instance. Better to just recreate the correct DNS
						record on any change.
					</aside>
				</section>

				<section>
					<h3>Lambda (pseudo) code</h3>
					<pre><code data-trim>
						container_ips = {}

						container_list = get_containers(task)
								host_ip = get_ecs_instance_ip(cluster_arn=cluster_arn,
								                              ecs_instance_arn=instance_arn)

								for container in container_list:
									dns_name = container.name + '.' + DNS_ZONE + '.'

									if dns_name not in container_ips:
										container_ips[dns_name] = set()

									if container.last_status == ContainerStatus.RUNNING:
										container_ips[dns_name].add(host_ip)

						# Update DNS records for all containers
						for dns_name in container_ips:
							print(f'Updating {dns_name}, new IPs: {container_ips[dns_name]}')
							update_zone(dns_name, container_ips[dns_name])
					</code></pre>

					<aside class="notes">
						Actual code is a 'little' longer. But this is the core.
					</aside>
				</section>

				<section class="center">
					<div class="title_card">
						<h1>Questions?</h1>
					</div>
				</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				controls: false,
				width: 1920,
				height: 1080,
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
